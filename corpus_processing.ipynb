{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjective position rates in a corpus of Argentinean Spanish\n",
    "Juan Berrios | juanberrios@pitt.edu | Last updated: October 4, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary and overview of the data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The purpose of the code included in this notebook is to build a `DataFrame` object from the `.txt` files in the Argentinian corpus directory. Adjective position rates for 6 adjective lexemes are extrated from the resulting data frame. The corpus I am using is the [*Corpus del español*](https://www.corpusdelespanol.org/); more specifically the [Web/Dialects](https://www.corpusdelespanol.org/web-dial/) corpus. While the corpus is searchable online, it is also possible to access the full data set for those wishing to do computational analyses, such as this. It is necessary to purchase a license to do so. I am authorized to use it through the license of the [Department of Linguistics](https://www.linguistics.pitt.edu/). Samples for the different formats can be downloaded from the [official website](https://www.corpusdata.org/formats.asp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents:**\n",
    "1. [Preparation](#1.-Preparation)  includes the necessary preparations.\n",
    "2. [Loading files](#2.-Loading-files)  includes code for loading the files, turning them into a data frame, and cleaning them using one of the `.txt` files as a sample.\n",
    "3. [Processing corpus directories](#3.-Processing-corpus-directories)  includes code for performing the operations on a corpus directory containing all the text files for Argentinean Spanish. The resulting data frames is stored as a `.pkl` file in case further processing is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading libraries and additional settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import glob, pickle, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Turning pretty print off:\n",
    "%pprint\n",
    "\n",
    "#Releasing all output:                                            \n",
    "from IPython.core.interactiveshell import InteractiveShell #Prints all commands rather than the last one.\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `.txt` files are very large. For testing purposes, I'll use only one of them as a start. The files are also tab-delimited. The columns correspond to an ID for the source text, an ID for the token, the token (word), the lemma, and the POS. I will hence use those for column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../../adjective_position/data/cde/wlp_AR-tez/ar-b-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SourceID', 'TokenID', 'Word', 'Lemma', 'POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First row is ignored because it corresponds to an identifier for the .txt file.\n",
    "\n",
    "df = pd.read_csv(fname,sep='\\t',encoding ='iso-8859-1',skiprows=[0],header=None,names=cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10087127, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #Size of the raw data frame in rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2232878917</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>m$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2232878918</td>\n",
       "      <td>tipos</td>\n",
       "      <td>tipo</td>\n",
       "      <td>nmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2232878919</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2232878920</td>\n",
       "      <td>sexo</td>\n",
       "      <td>sexo</td>\n",
       "      <td>nms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2232878921</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087122</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712654</td>\n",
       "      <td>política</td>\n",
       "      <td>político</td>\n",
       "      <td>jfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087123</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712655</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087124</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712656</td>\n",
       "      <td>la</td>\n",
       "      <td>la</td>\n",
       "      <td>ld-fs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087125</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712657</td>\n",
       "      <td>Nación</td>\n",
       "      <td>nación</td>\n",
       "      <td>nms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087126</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712658</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10087127 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID      Word     Lemma      POS\n",
       "0               10  2232878917        10        10       m$\n",
       "1               10  2232878918     tipos      tipo  nmp    \n",
       "2               10  2232878919        de        de        e\n",
       "3               10  2232878920      sexo      sexo  nms    \n",
       "4               10  2232878921         .        $.        y\n",
       "...            ...         ...       ...       ...      ...\n",
       "10087122    108200   393712654  política  político  jfs    \n",
       "10087123    108200   393712655        de        de        e\n",
       "10087124    108200   393712656        la        la    ld-fs\n",
       "10087125    108200   393712657    Nación    nación  nms    \n",
       "10087126    108200   393712658         .        $.        y\n",
       "\n",
       "[10087127 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #First and last five rows. Dimensions on the bottom. Data were loaded correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before removing unneeded rows, it is necessary to add information about the word preceding and following each token, as well as their corresponding POS tags, so that it is possible to determine rates of pre- and post-position later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Previous_word'] = df['Word'].shift() #Extracting previous word and POS tag\n",
    "df['Previous_POS'] = df['POS'].shift() \n",
    "df['Following_word'] = df['Word'].shift(-1) #Extracting following word and POS tag\n",
    "df['Following_POS'] = df['POS'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Previous_word</th>\n",
       "      <th>Previous_POS</th>\n",
       "      <th>Following_word</th>\n",
       "      <th>Following_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2232878917</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>m$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tipos</td>\n",
       "      <td>nmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2232878918</td>\n",
       "      <td>tipos</td>\n",
       "      <td>tipo</td>\n",
       "      <td>nmp</td>\n",
       "      <td>10</td>\n",
       "      <td>m$</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2232878919</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "      <td>tipos</td>\n",
       "      <td>nmp</td>\n",
       "      <td>sexo</td>\n",
       "      <td>nms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2232878920</td>\n",
       "      <td>sexo</td>\n",
       "      <td>sexo</td>\n",
       "      <td>nms</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "      <td>.</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2232878921</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>y</td>\n",
       "      <td>sexo</td>\n",
       "      <td>nms</td>\n",
       "      <td>.</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087122</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712654</td>\n",
       "      <td>política</td>\n",
       "      <td>político</td>\n",
       "      <td>jfs</td>\n",
       "      <td>participación</td>\n",
       "      <td>nfs</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087123</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712655</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "      <td>política</td>\n",
       "      <td>jfs</td>\n",
       "      <td>la</td>\n",
       "      <td>ld-fs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087124</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712656</td>\n",
       "      <td>la</td>\n",
       "      <td>la</td>\n",
       "      <td>ld-fs</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "      <td>Nación</td>\n",
       "      <td>nms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087125</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712657</td>\n",
       "      <td>Nación</td>\n",
       "      <td>nación</td>\n",
       "      <td>nms</td>\n",
       "      <td>la</td>\n",
       "      <td>ld-fs</td>\n",
       "      <td>.</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087126</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712658</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>y</td>\n",
       "      <td>Nación</td>\n",
       "      <td>nms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10087127 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID      Word     Lemma      POS  Previous_word  \\\n",
       "0               10  2232878917        10        10       m$            NaN   \n",
       "1               10  2232878918     tipos      tipo  nmp                 10   \n",
       "2               10  2232878919        de        de        e          tipos   \n",
       "3               10  2232878920      sexo      sexo  nms                 de   \n",
       "4               10  2232878921         .        $.        y           sexo   \n",
       "...            ...         ...       ...       ...      ...            ...   \n",
       "10087122    108200   393712654  política  político  jfs      participación   \n",
       "10087123    108200   393712655        de        de        e       política   \n",
       "10087124    108200   393712656        la        la    ld-fs             de   \n",
       "10087125    108200   393712657    Nación    nación  nms                 la   \n",
       "10087126    108200   393712658         .        $.        y         Nación   \n",
       "\n",
       "         Previous_POS Following_word Following_POS  \n",
       "0                 NaN          tipos       nmp      \n",
       "1                  m$             de             e  \n",
       "2             nmp               sexo       nms      \n",
       "3                   e              .             y  \n",
       "4             nms                  .             y  \n",
       "...               ...            ...           ...  \n",
       "10087122      nfs                 de             e  \n",
       "10087123      jfs                 la         ld-fs  \n",
       "10087124            e         Nación       nms      \n",
       "10087125        ld-fs              .             y  \n",
       "10087126      nms                NaN           NaN  \n",
       "\n",
       "[10087127 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #New columns have been added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that concordances have been added, we are keeping only the rows of interest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_lexemes = ['grande', 'bueno', 'nuevo', 'rudo', 'fresco', 'llano'] #Adjectives under study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Lemma'].isin(adj_lexemes)] #Keep only the rows of interest in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Previous_word</th>\n",
       "      <th>Previous_POS</th>\n",
       "      <th>Following_word</th>\n",
       "      <th>Following_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>30</td>\n",
       "      <td>2245675103</td>\n",
       "      <td>nueva</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jfs</td>\n",
       "      <td>la</td>\n",
       "      <td>ld-fs</td>\n",
       "      <td>integrante</td>\n",
       "      <td>nms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>30</td>\n",
       "      <td>2245675579</td>\n",
       "      <td>nueva</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jfs</td>\n",
       "      <td>Una</td>\n",
       "      <td>li-fs</td>\n",
       "      <td>pareja</td>\n",
       "      <td>nfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>30</td>\n",
       "      <td>2245675680</td>\n",
       "      <td>buenos</td>\n",
       "      <td>bueno</td>\n",
       "      <td>jmp</td>\n",
       "      <td>ni</td>\n",
       "      <td>cc</td>\n",
       "      <td>ni</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>30</td>\n",
       "      <td>2245675707</td>\n",
       "      <td>gran</td>\n",
       "      <td>grande</td>\n",
       "      <td>j</td>\n",
       "      <td>,</td>\n",
       "      <td>y</td>\n",
       "      <td>herramienta</td>\n",
       "      <td>nfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861</th>\n",
       "      <td>30</td>\n",
       "      <td>2245675793</td>\n",
       "      <td>buena</td>\n",
       "      <td>bueno</td>\n",
       "      <td>jfs</td>\n",
       "      <td>la</td>\n",
       "      <td>ld-fs</td>\n",
       "      <td>onda</td>\n",
       "      <td>nfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086814</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712346</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jms</td>\n",
       "      <td>el</td>\n",
       "      <td>ld-ms</td>\n",
       "      <td>hombre</td>\n",
       "      <td>nms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086923</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712455</td>\n",
       "      <td>nueva</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jfs</td>\n",
       "      <td>la</td>\n",
       "      <td>ld-fs</td>\n",
       "      <td>Nación</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086996</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712528</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jms</td>\n",
       "      <td>como</td>\n",
       "      <td>r</td>\n",
       "      <td>protagonista</td>\n",
       "      <td>nms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087097</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712629</td>\n",
       "      <td>Nuevo</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jms</td>\n",
       "      <td>?</td>\n",
       "      <td>y</td>\n",
       "      <td>concepto</td>\n",
       "      <td>nms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10087108</th>\n",
       "      <td>108200</td>\n",
       "      <td>393712640</td>\n",
       "      <td>Nueva</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jfs</td>\n",
       "      <td>.</td>\n",
       "      <td>y</td>\n",
       "      <td>concepción</td>\n",
       "      <td>nfs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28816 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID    Word   Lemma      POS Previous_word  \\\n",
       "2171            30  2245675103   nueva   nuevo  jfs                la   \n",
       "2647            30  2245675579   nueva   nuevo  jfs               Una   \n",
       "2748            30  2245675680  buenos   bueno  jmp                ni   \n",
       "2775            30  2245675707    gran  grande        j             ,   \n",
       "2861            30  2245675793   buena   bueno  jfs                la   \n",
       "...            ...         ...     ...     ...      ...           ...   \n",
       "10086814    108200   393712346   nuevo   nuevo  jms                el   \n",
       "10086923    108200   393712455   nueva   nuevo  jfs                la   \n",
       "10086996    108200   393712528   nuevo   nuevo  jms              como   \n",
       "10087097    108200   393712629   Nuevo   nuevo  jms                 ?   \n",
       "10087108    108200   393712640   Nueva   nuevo  jfs                 .   \n",
       "\n",
       "         Previous_POS Following_word Following_POS  \n",
       "2171            ld-fs     integrante       nms      \n",
       "2647            li-fs         pareja       nfs      \n",
       "2748               cc             ni            cc  \n",
       "2775                y    herramienta       nfs      \n",
       "2861            ld-fs           onda       nfs      \n",
       "...               ...            ...           ...  \n",
       "10086814        ld-ms         hombre       nms      \n",
       "10086923        ld-fs         Nación             o  \n",
       "10086996            r   protagonista       nms      \n",
       "10087097            y       concepto       nms      \n",
       "10087108            y     concepción       nfs      \n",
       "\n",
       "[28816 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #First and last five rows. Dimensions on the bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lastly, it is necessary to remove rows that are not needed for analysis (e.g., those containing lexemes that are not adjectives, or adjectives used after a copula rather than with a noun):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() #Dropping Nan values which might cause errors later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jfs    ', 'jmp    ', 'j', 'jms    ', 'jfp    ', 'r', 'o',\n",
       "       'nmp    ', 'nms    ', 'i'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['POS'].unique() #These are the POS currently included. Only those containing 'j' (adjectives) are to be kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['POS'].str.contains('j')] #Removes unneeded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jfs    ', 'jmp    ', 'j', 'jms    ', 'jfp    '], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['POS'].unique() #Values removed. There is also unnecessary white space which can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.applymap(lambda x: x.rstrip() if type(x)==str else x) #Remove all white spaces in data frame if type is str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jfs', 'jmp', 'j', 'jms', 'jfp'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['POS'].unique() #Effectively removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another cleaning step is to remove tokens that do not correspond to adjective-noun combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Previous_POS'].str.startswith('n')|df['Following_POS'].str.startswith('n')] #Removes unneeded rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The (grammatical) number of each token is relevant information to determine rates later. Let's make the column more transparent and create new columns in the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build dictionaries that map POS into desired number values:\n",
    "\n",
    "number_dict = {'j': 'unknown', 'jms': 'singular', 'jfs': 'singular', 'jmp': 'plural', \n",
    "                  'jfp': 'plural'}\n",
    "\n",
    "#Note that some tokens are not tagged for number. As a solution,I'll create an 'Unknown label'. It is also possible \n",
    "#to write code that will tag them based on certain patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping values to new column\n",
    "\n",
    "df['Number'] = df['POS'].map(number_dict) #Map new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Previous_word</th>\n",
       "      <th>Previous_POS</th>\n",
       "      <th>Following_word</th>\n",
       "      <th>Following_POS</th>\n",
       "      <th>Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6547047</th>\n",
       "      <td>65560</td>\n",
       "      <td>2419103415</td>\n",
       "      <td>buenos</td>\n",
       "      <td>bueno</td>\n",
       "      <td>jmp</td>\n",
       "      <td>2</td>\n",
       "      <td>m$</td>\n",
       "      <td>delanteros</td>\n",
       "      <td>nmp</td>\n",
       "      <td>plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768571</th>\n",
       "      <td>12920</td>\n",
       "      <td>1580985524</td>\n",
       "      <td>nuevas</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jfp</td>\n",
       "      <td>son</td>\n",
       "      <td>vip-3p</td>\n",
       "      <td>pruebas</td>\n",
       "      <td>nfp</td>\n",
       "      <td>plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576385</th>\n",
       "      <td>32990</td>\n",
       "      <td>1769309363</td>\n",
       "      <td>nuevas</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jfp</td>\n",
       "      <td>las</td>\n",
       "      <td>ld-fp</td>\n",
       "      <td>posibilidades</td>\n",
       "      <td>nfp</td>\n",
       "      <td>plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778649</th>\n",
       "      <td>104310</td>\n",
       "      <td>2301100275</td>\n",
       "      <td>buen</td>\n",
       "      <td>bueno</td>\n",
       "      <td>j</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "      <td>repulgue</td>\n",
       "      <td>n</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5584831</th>\n",
       "      <td>53570</td>\n",
       "      <td>641167647</td>\n",
       "      <td>grandes</td>\n",
       "      <td>grande</td>\n",
       "      <td>jmp</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "      <td>bodegas</td>\n",
       "      <td>nfp</td>\n",
       "      <td>plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371770</th>\n",
       "      <td>41690</td>\n",
       "      <td>968266488</td>\n",
       "      <td>buenos</td>\n",
       "      <td>bueno</td>\n",
       "      <td>jmp</td>\n",
       "      <td>dan</td>\n",
       "      <td>vip-3p</td>\n",
       "      <td>resultados</td>\n",
       "      <td>n</td>\n",
       "      <td>plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003391</th>\n",
       "      <td>26630</td>\n",
       "      <td>803596764</td>\n",
       "      <td>grandes</td>\n",
       "      <td>grande</td>\n",
       "      <td>jmp</td>\n",
       "      <td>poetas</td>\n",
       "      <td>nmp</td>\n",
       "      <td>como</td>\n",
       "      <td>e</td>\n",
       "      <td>plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59807</th>\n",
       "      <td>540</td>\n",
       "      <td>2629794278</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jms</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "      <td>hombre</td>\n",
       "      <td>nms</td>\n",
       "      <td>singular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627714</th>\n",
       "      <td>5620</td>\n",
       "      <td>773097723</td>\n",
       "      <td>nuevas</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jfp</td>\n",
       "      <td>las</td>\n",
       "      <td>ld-fp</td>\n",
       "      <td>generaciones</td>\n",
       "      <td>nfp</td>\n",
       "      <td>plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313475</th>\n",
       "      <td>9800</td>\n",
       "      <td>1256300105</td>\n",
       "      <td>nuevos</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>jmp</td>\n",
       "      <td>los</td>\n",
       "      <td>ld-mp</td>\n",
       "      <td>smartphones</td>\n",
       "      <td>n</td>\n",
       "      <td>plural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SourceID     TokenID     Word   Lemma  POS Previous_word  \\\n",
       "6547047     65560  2419103415   buenos   bueno  jmp             2   \n",
       "1768571     12920  1580985524   nuevas   nuevo  jfp           son   \n",
       "3576385     32990  1769309363   nuevas   nuevo  jfp           las   \n",
       "9778649    104310  2301100275     buen   bueno    j            un   \n",
       "5584831     53570   641167647  grandes  grande  jmp            de   \n",
       "4371770     41690   968266488   buenos   bueno  jmp           dan   \n",
       "3003391     26630   803596764  grandes  grande  jmp        poetas   \n",
       "59807         540  2629794278    nuevo   nuevo  jms            un   \n",
       "627714       5620   773097723   nuevas   nuevo  jfp           las   \n",
       "1313475      9800  1256300105   nuevos   nuevo  jmp           los   \n",
       "\n",
       "        Previous_POS Following_word Following_POS    Number  \n",
       "6547047           m$     delanteros           nmp    plural  \n",
       "1768571       vip-3p        pruebas           nfp    plural  \n",
       "3576385        ld-fp  posibilidades           nfp    plural  \n",
       "9778649        li-ms       repulgue             n   unknown  \n",
       "5584831            e        bodegas           nfp    plural  \n",
       "4371770       vip-3p     resultados             n    plural  \n",
       "3003391          nmp           como             e    plural  \n",
       "59807          li-ms         hombre           nms  singular  \n",
       "627714         ld-fp   generaciones           nfp    plural  \n",
       "1313475        ld-mp    smartphones             n    plural  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10) #Ten sample rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's take care of the unknown value to finish. The information needed can be extrated from POS columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "singular    7259\n",
       "unknown     6627\n",
       "plural      5253\n",
       "Name: Number, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Number'].value_counts() #There are 7202 'unknown' values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that there's a defined process flow, the next step is to apply all operations to each `.txt` file in the directory in a streamlined fashion. I'll delete unneeded objects before proceding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del fname\n",
    "del cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Processing corpus directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a first step, knowing now that the operations above are sucessful, I will define functions to make the processing pipeline for the full data drame object more efficient and streamlined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDF(fname):\n",
    "    \"\"\"Turns tab-delimited file into a data frame\"\"\"\n",
    "    cols = ['SourceID', 'TokenID', 'Word', 'Lemma', 'POS']\n",
    "    df = pd.read_csv(fname,sep='\\t',encoding ='iso-8859-1',skiprows=[0],header=None,names=cols)\n",
    "    df = df.dropna() #Dropping Nan values which might cause errors later.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrounding_words(df):\n",
    "    \"\"\"Adds four columns containing the token's previous and folling word and corresponding POS tags\"\"\"\n",
    "    df['Previous_word'] = df['Word'].shift()\n",
    "    df['Previous_POS'] = df['POS'].shift() \n",
    "    df['Following_word'] = df['Word'].shift(-1)\n",
    "    df['Following_POS'] = df['POS'].shift(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_lexemes(df):\n",
    "    \"\"\"Keep only rows contaning adjective lexemes under study\"\"\"\n",
    "    adj_lexemes = ['grande', 'bueno', 'nuevo', 'rudo', 'fresco', 'llano'] #Adjectives under study\n",
    "    df = df[df['Lemma'].isin(adj_lexemes)] #Keep only the rows of interest in the data frame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_POS(df):\n",
    "    \"\"\"Removes white spaces and rows containing extraneous POS\"\"\"\n",
    "    df = df.applymap(lambda x: x.rstrip() if type(x)==str else x) #Removes white space\n",
    "    df = df[df['POS'].str.contains('j')] #Removes non-adjective tokens\n",
    "    df = df[df['Previous_POS'].str.startswith('n')|df['Following_POS'].str.startswith('n')] #Removes non A-N rows \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_number(df):\n",
    "    \"\"\"Adds column specifying grammtical information for each token\"\"\"\n",
    "    number_dict = {'j': 'unknown', 'jms': 'singular', 'jfs': 'singular', 'jmp': 'plural', \n",
    "                  'jfp': 'plural'}\n",
    "    df['Number'] = df['POS'].map(number_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's set the directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../adjective_position/data/cde/wlp_AR-tez\\\\ar-b-0.txt'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = '../../adjective_position/data/cde/wlp_AR-tez/ar-b-0.txt'\n",
    "\n",
    "corpus_dir = '../../adjective_position/data/cde/'\n",
    "ar_dir = glob.glob(corpus_dir + 'wlp_AR-tez/*.txt')\n",
    "ar_dir[0] #First file found in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ar_dir) #There are 20 files in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Previous_word</th>\n",
       "      <th>Previous_POS</th>\n",
       "      <th>Following_word</th>\n",
       "      <th>Following_POS</th>\n",
       "      <th>Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SourceID, TokenID, Word, Lemma, POS, Previous_word, Previous_POS, Following_word, Following_POS, Number]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_df = pd.DataFrame(columns=['SourceID', 'TokenID', 'Word', 'Lemma', 'POS', 'Previous_word',\n",
    "       'Previous_POS', 'Following_word', 'Following_POS', 'Number']) #Builds a new, empty data frame object.\n",
    "ar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in ar_dir:                            #Create a master data frame \n",
    "    df = toDF(fname)                             \n",
    "    df = surrounding_words(df)\n",
    "    df = adj_lexemes(df)\n",
    "    df = clean_POS(df)\n",
    "    df = add_number(df)                   \n",
    "    ar_df = pd.concat([ar_df, df], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Following_POS</th>\n",
       "      <th>Following_word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Number</th>\n",
       "      <th>POS</th>\n",
       "      <th>Previous_POS</th>\n",
       "      <th>Previous_word</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>nms</td>\n",
       "      <td>integrante</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>singular</td>\n",
       "      <td>jfs</td>\n",
       "      <td>ld-fs</td>\n",
       "      <td>la</td>\n",
       "      <td>30</td>\n",
       "      <td>2245675103</td>\n",
       "      <td>nueva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>nfs</td>\n",
       "      <td>pareja</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>singular</td>\n",
       "      <td>jfs</td>\n",
       "      <td>li-fs</td>\n",
       "      <td>Una</td>\n",
       "      <td>30</td>\n",
       "      <td>2245675579</td>\n",
       "      <td>nueva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>nfs</td>\n",
       "      <td>herramienta</td>\n",
       "      <td>grande</td>\n",
       "      <td>unknown</td>\n",
       "      <td>j</td>\n",
       "      <td>y</td>\n",
       "      <td>,</td>\n",
       "      <td>30</td>\n",
       "      <td>2245675707</td>\n",
       "      <td>gran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861</th>\n",
       "      <td>nfs</td>\n",
       "      <td>onda</td>\n",
       "      <td>bueno</td>\n",
       "      <td>singular</td>\n",
       "      <td>jfs</td>\n",
       "      <td>ld-fs</td>\n",
       "      <td>la</td>\n",
       "      <td>30</td>\n",
       "      <td>2245675793</td>\n",
       "      <td>buena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>nms</td>\n",
       "      <td>representante</td>\n",
       "      <td>nuevo</td>\n",
       "      <td>singular</td>\n",
       "      <td>jms</td>\n",
       "      <td>dp-</td>\n",
       "      <td>su</td>\n",
       "      <td>40</td>\n",
       "      <td>2407904224</td>\n",
       "      <td>nuevo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10441803</th>\n",
       "      <td>nms</td>\n",
       "      <td>esfuerzo</td>\n",
       "      <td>grande</td>\n",
       "      <td>unknown</td>\n",
       "      <td>j</td>\n",
       "      <td>li-ms</td>\n",
       "      <td>un</td>\n",
       "      <td>1405719</td>\n",
       "      <td>1907146676</td>\n",
       "      <td>gran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10441944</th>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>ponga</td>\n",
       "      <td>grande</td>\n",
       "      <td>singular</td>\n",
       "      <td>jms</td>\n",
       "      <td>nms</td>\n",
       "      <td>equipo</td>\n",
       "      <td>1405719</td>\n",
       "      <td>1907146817</td>\n",
       "      <td>grande</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10442385</th>\n",
       "      <td>nms</td>\n",
       "      <td>comienzo</td>\n",
       "      <td>bueno</td>\n",
       "      <td>unknown</td>\n",
       "      <td>j</td>\n",
       "      <td>li-ms</td>\n",
       "      <td>un</td>\n",
       "      <td>1405729</td>\n",
       "      <td>1909545195</td>\n",
       "      <td>buen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10442494</th>\n",
       "      <td>y</td>\n",
       "      <td>,</td>\n",
       "      <td>bueno</td>\n",
       "      <td>singular</td>\n",
       "      <td>jms</td>\n",
       "      <td>n</td>\n",
       "      <td>@</td>\n",
       "      <td>1405729</td>\n",
       "      <td>1909545304</td>\n",
       "      <td>bueno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10442795</th>\n",
       "      <td>nms</td>\n",
       "      <td>parte</td>\n",
       "      <td>grande</td>\n",
       "      <td>unknown</td>\n",
       "      <td>j</td>\n",
       "      <td>vis-3p</td>\n",
       "      <td>forjaron</td>\n",
       "      <td>1405749</td>\n",
       "      <td>1914742158</td>\n",
       "      <td>gran</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374161 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Following_POS Following_word   Lemma    Number  POS Previous_POS  \\\n",
       "2171               nms     integrante   nuevo  singular  jfs        ld-fs   \n",
       "2647               nfs         pareja   nuevo  singular  jfs        li-fs   \n",
       "2775               nfs    herramienta  grande   unknown    j            y   \n",
       "2861               nfs           onda   bueno  singular  jfs        ld-fs   \n",
       "3415               nms  representante   nuevo  singular  jms          dp-   \n",
       "...                ...            ...     ...       ...  ...          ...   \n",
       "10441803           nms       esfuerzo  grande   unknown    j        li-ms   \n",
       "10441944      vsp-1/3s          ponga  grande  singular  jms          nms   \n",
       "10442385           nms       comienzo   bueno   unknown    j        li-ms   \n",
       "10442494             y              ,   bueno  singular  jms            n   \n",
       "10442795           nms          parte  grande   unknown    j       vis-3p   \n",
       "\n",
       "         Previous_word SourceID     TokenID    Word  \n",
       "2171                la       30  2245675103   nueva  \n",
       "2647               Una       30  2245675579   nueva  \n",
       "2775                 ,       30  2245675707    gran  \n",
       "2861                la       30  2245675793   buena  \n",
       "3415                su       40  2407904224   nuevo  \n",
       "...                ...      ...         ...     ...  \n",
       "10441803            un  1405719  1907146676    gran  \n",
       "10441944        equipo  1405719  1907146817  grande  \n",
       "10442385            un  1405729  1909545195    buen  \n",
       "10442494             @  1405729  1909545304   bueno  \n",
       "10442795      forjaron  1405749  1914742158    gran  \n",
       "\n",
       "[374161 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_df #First and last five rows and dimensions on the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Following_POS', 'Following_word', 'Lemma', 'Number', 'POS',\n",
       "       'Previous_POS', 'Previous_word', 'SourceID', 'TokenID', 'Word'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_df.keys() #Order is shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_df = ar_df[['SourceID', 'TokenID', 'Word', 'Lemma', 'POS', 'Previous_word',\n",
    "       'Previous_POS', 'Following_word', 'Following_POS', 'Number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SourceID', 'TokenID', 'Word', 'Lemma', 'POS', 'Previous_word',\n",
       "       'Previous_POS', 'Following_word', 'Following_POS', 'Number'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_df.keys() #Order restablished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Storing the master data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_df.to_pickle('pkl/ar_DF.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
